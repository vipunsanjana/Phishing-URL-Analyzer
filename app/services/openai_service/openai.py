import json
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage
from langchain_text_splitters import RecursiveCharacterTextSplitter
from app.utils import constants
from app.utils.config import OPENAI_API_KEY, TEMPERATURE, GPT_MODEL
from app.utils.html_context import process_tags
from app.utils.prompt_template import PHISHING_ANALYSIS_PROMPT

def generate_response(url, html, text):
    """
    Generates a response from GPT based on the given URL, HTML content, and text.
    
    Args:
        url (str): The URL being analyzed.
        html (str): The HTML content associated with the URL.
        text (str): Extracted text from the HTML content.
    
    Returns:
        dict: A JSON response generated by GPT.
    
    Raises:
        Exception: If an error occurs during GPT processing or JSON parsing.
    """
    try:
        chat_model = ChatOpenAI(model_name=GPT_MODEL, temperature=TEMPERATURE, openai_api_key=OPENAI_API_KEY)

        # Process HTML to extract tags
        filtered_tags = process_tags(html)
        a_tags = filtered_tags.a_tags
        script_tags = filtered_tags.script_tags

        formatted_prompt = constants.SUPPORT_PROMPT+ PHISHING_ANALYSIS_PROMPT.format(
            url=url,
            text=text,
            a_tags=a_tags,
            script_tags=script_tags
        ) 

        if len(formatted_prompt) > 127000:
            constants.LOGGER.warning("Prompt is too long, truncating to 127000 characters.")
            formatted_prompt = formatted_prompt[:127000]

        # Always assign chunks, even if truncated
        chunks = [formatted_prompt]

        responses = []
        for chunk in chunks:
            message = HumanMessage(content=chunk)
            response = chat_model.invoke([message])
            responses.append(response.content)

        full_response = " ".join(responses)
        json_response = json.loads(full_response)
        
        return json_response

    except json.JSONDecodeError as e:
        constants.LOGGER.error(f"Error parsing JSON response: {str(e)}")
        raise Exception(f"Failed to parse JSON response: {e}")
    except Exception as e:
        constants.LOGGER.error(f"Error during GPT generation: {str(e)}")
        raise Exception(f"Error generating GPT response: {str(e)}")
